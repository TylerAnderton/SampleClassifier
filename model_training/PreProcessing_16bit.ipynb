{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing 16bit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to build a pipeline that will preprocess samples on my local machine to prepare them for use in training the classification model.\n",
    "\n",
    "This pipeline will perform three main functions.\n",
    "\n",
    "1. Crawl through local folders of samples previously downloaded from Splice.com and load all files found into the pipeline.\n",
    "2. Use keywords in the file names to determine the proper training labels and filter out files that would be detrimental to training.\n",
    "3. Standardize samplerates, volume normalization, and sample length before writing new wav files that contain the training labels in their names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my initial attempts at implementing this pipeline, I ran into issues with mapping my processing functions and training the classification model on the training set. This is partially due to my use of librosa to load audio files in the model-training pipeline. I will attempt to only use tensorflow in the model-training pipeline, but tf.audio.decode_wav only accepts 16bit wav files. To accomodate this, I will need to alter this preprocessing pipeline to write our training samples as 16bit wav files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build and test functions on single samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Define test filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHORT_SAMPLE_FILEPATH: str = '/Users/tyler/2TB SSD/Samples/Splice - TYX/sounds/packs/8-Bitstep/PL0347_WAV_ACID_8_-_Bitstep/Prime_Loops_-_8-Bitstep/Drum_One-Shots/Kicks/'\n",
    "SHORT_SAMPLE_FILENAME: str = 'Kick_06.wav'\n",
    "LONG_SAMPLE_FILEPATH: str = '/Users/tyler/2TB SSD/Samples/Splice - TYX/sounds/packs/Bedroom Pop/synth/Loops/'\n",
    "LONG_SAMPLE_FILENAME: str = 'JP_BP_synth_loop_wet_simple_124_Gmin.wav'\n",
    "\n",
    "NEG_SAMPLE_FILEPATH: str = '/Users/tyler/2TB SSD/Samples/Splice - TYX/sounds/packs/Industry Vol. 1/'\n",
    "NEG_SAMPLE_FILENAME: str = 'AirCompressorRelease_SFXB.2.wav'\n",
    "\n",
    "ASD_SAMPLE_FILEPATH: str = '/Users/tyler/2TB SSD/Samples/Splice - TYX/sounds/packs/deadmau5 - Chimaera'\n",
    "ASD_SAMPLE_FILENAME: str = 'mau5_kick_04_Fm.wav.asd'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Define target sample rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All samples in this library are sampled at least 44.1kHz. As a safe bet against potential aliasing of high frequencies, we will downsample to 44.1kHz. If training a model with a larger dataset, or if otherwise concerned about storage overhead, we could downsample to 22kHz, but we would risk aliasing effects that could interfere with our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SAMPLE_RATE: int = 44100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Load audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns array representing audio sample at the target sample rate and the sample file name for labeling\n",
    "def load_sample(filepath: str, filename: str) -> tuple[list[float], str]:\n",
    "    full_file_path: str = os.path.join(filepath, filename)\n",
    "    audio, sample_rate = librosa.load(full_file_path, mono=True, sr=TARGET_SAMPLE_RATE)\n",
    "    return (audio, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.3841858e-07,  2.3841858e-07,  1.7881393e-07, ...,\n",
       "        -1.1920929e-07,  0.0000000e+00, -2.3841858e-07], dtype=float32),\n",
       " 'Kick_06.wav')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_test = load_sample(SHORT_SAMPLE_FILEPATH, SHORT_SAMPLE_FILENAME)\n",
    "short_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00062246, -0.00097344, -0.00067311, ..., -0.01063265,\n",
       "        -0.01121341,  0.        ], dtype=float32),\n",
       " 'JP_BP_synth_loop_wet_simple_124_Gmin.wav')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_test = load_sample(LONG_SAMPLE_FILEPATH, LONG_SAMPLE_FILENAME)\n",
    "long_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Label samples appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_percussion(sample: tuple[list[float], str]) -> tuple[list[float], str]:\n",
    "    audio, filename = sample\n",
    "    \n",
    "    if re.search(r'kick', filename.lower()):\n",
    "        return (audio, 'kick')\n",
    "    elif re.search(r'snare', filename.lower()):\n",
    "        return (audio,'snare')\n",
    "    elif re.search(r'clap', filename.lower()):\n",
    "        return (audio, 'clap')\n",
    "    elif re.search(r'hat', filename.lower()):\n",
    "        return (audio, 'hat')\n",
    "    elif re.search(r'crash|ride|splash|china|trash', filename.lower()):\n",
    "        return (audio, 'cymbal')\n",
    "    elif re.search(r'perc|tom', filename.lower()):\n",
    "        return (audio, 'perc')\n",
    "    else:\n",
    "        return (audio, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sustains(sample: tuple[list[float], str]) -> tuple[list[float], str]:\n",
    "    audio, filename = sample\n",
    "\n",
    "    if re.search(r'808', filename.lower()):\n",
    "        return (audio, '808')\n",
    "    elif re.search(r'bass|reese', filename.lower()):\n",
    "        return (audio, 'bass')\n",
    "    elif re.search(r'vocal|vox|shout|chant', filename.lower()):\n",
    "        return (audio, 'vocal')\n",
    "    elif re.search(r'synth|pad|drone|atmosphere', filename.lower()):\n",
    "        return (audio,'synth')\n",
    "    elif re.search(r'guitar', filename.lower()):\n",
    "        return (audio, 'guitar')\n",
    "    else:\n",
    "        return (audio, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to skip .asd filenames when implementing pipeline\n",
    "def label_sample(sample: tuple[list[float], str])-> tuple[list[float], str]:\n",
    "    audio, filename = sample\n",
    "    audio, label = audio, None\n",
    "\n",
    "    # skip irrelevant samples\n",
    "    if re.search(r'wavetable|fx|fill', filename):\n",
    "        return audio, label\n",
    "\n",
    "    # attempt to label percussion\n",
    "    if not re.search(r'loop', filename.lower()):\n",
    "        audio, label = label_percussion(sample)\n",
    "\n",
    "    # attempt to label sustains\n",
    "    if not label:\n",
    "        audio, label = label_sustains(sample)\n",
    "\n",
    "    return (audio, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.3841858e-07,  2.3841858e-07,  1.7881393e-07, ...,\n",
       "        -1.1920929e-07,  0.0000000e+00, -2.3841858e-07], dtype=float32),\n",
       " 'kick')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_test_labeled = label_sample(short_test)\n",
    "short_test_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00062246, -0.00097344, -0.00067311, ..., -0.01063265,\n",
       "        -0.01121341,  0.        ], dtype=float32),\n",
       " 'synth')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_test_labeled = label_sample(long_test)\n",
    "long_test_labeled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Trim or pad audio to standard length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDARD_SAMPLE_LENGTH_SEC: int = 3\n",
    "STANDARD_SAMPLE_LENGTH_SAMPLES: int = TARGET_SAMPLE_RATE * STANDARD_SAMPLE_LENGTH_SEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_sample_length(sample: tuple[list[float], str]) -> tuple[list[float], str]:\n",
    "    audio, label = sample\n",
    "\n",
    "    audio = audio[:STANDARD_SAMPLE_LENGTH_SAMPLES]\n",
    "    \n",
    "    zero_padding = np.zeros(STANDARD_SAMPLE_LENGTH_SAMPLES - len(audio), dtype=float)\n",
    "    return (np.append(audio, zero_padding), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.38418579e-07, 2.38418579e-07, 1.78813934e-07, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'kick')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_test_std = trim_sample_length(short_test_labeled)\n",
    "short_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_test_std[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00062246, -0.00097344, -0.00067311, ..., -0.01021675,\n",
       "        -0.01180182, -0.01450411]),\n",
       " 'synth')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_test_std = trim_sample_length(long_test_labeled)\n",
    "long_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132300,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_test_std[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Normalize audio volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sample(sample: tuple[list[float], str]) -> tuple[list[float], str]:\n",
    "    audio, label = sample\n",
    "    return (librosa.util.normalize(audio), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.00153468e-07, 3.00153468e-07, 2.25115101e-07, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'kick')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_test_norm = normalize_sample(short_test_std)\n",
    "short_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(short_test_norm[0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.0007198 , -0.00112567, -0.00077838, ..., -0.01181446,\n",
       "        -0.0136474 , -0.01677229]),\n",
       " 'synth')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_test_norm = normalize_sample(long_test_std)\n",
    "long_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(short_test_norm[0]).max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Write samples to new .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_SAMPLES_DIR: str = 'preprocessed_samples_16bit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCM_16': 'Signed 16 bit PCM',\n",
       " 'PCM_24': 'Signed 24 bit PCM',\n",
       " 'PCM_32': 'Signed 32 bit PCM',\n",
       " 'PCM_U8': 'Unsigned 8 bit PCM',\n",
       " 'FLOAT': '32 bit float',\n",
       " 'DOUBLE': '64 bit float',\n",
       " 'ULAW': 'U-Law',\n",
       " 'ALAW': 'A-Law',\n",
       " 'IMA_ADPCM': 'IMA ADPCM',\n",
       " 'MS_ADPCM': 'Microsoft ADPCM',\n",
       " 'GSM610': 'GSM 6.10',\n",
       " 'G721_32': '32kbs G721 ADPCM',\n",
       " 'NMS_ADPCM_16': '16kbs NMS ADPCM',\n",
       " 'NMS_ADPCM_24': '24kbs NMS ADPCM',\n",
       " 'NMS_ADPCM_32': '32kbs NMS ADPCM',\n",
       " 'MPEG_LAYER_III': 'MPEG Layer III'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.available_subtypes('WAV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sample_file(sample: tuple[list[float], str], sample_id: str) -> None:\n",
    "    audio, label = sample\n",
    "\n",
    "    file_name: str = f\"{label}_{sample_id.zfill(6)}.wav\"\n",
    "    file_path: str = os.path.join(PROCESSED_SAMPLES_DIR, file_name)\n",
    "\n",
    "    sf.write(file_path, audio, TARGET_SAMPLE_RATE, subtype='PCM_16', format='WAV') # changed from 24 to 16bit for compatibility with tensorflow decode_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sample_file(short_test_norm, '13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sample_file(long_test_norm, '57389')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8 Write wrapper function for all preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(filepath: str, filename: str, file_id: str) -> None:\n",
    "    sample_raw: tuple[list[float], str] = load_sample(filepath, filename)\n",
    "    sample_labelled: tuple[list[float], str] = label_sample(sample_raw)\n",
    "    if not sample_labelled[1]:\n",
    "        return\n",
    "    sample_trim: tuple[list[float], str] = trim_sample_length(sample_labelled)\n",
    "    sample_norm: tuple[list[float], str] = normalize_sample(sample_trim)\n",
    "    write_sample_file(sample_norm, file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_sample(SHORT_SAMPLE_FILEPATH, SHORT_SAMPLE_FILENAME, '6483')\n",
    "process_sample(NEG_SAMPLE_FILEPATH, NEG_SAMPLE_FILENAME, '36413')\n",
    "process_sample(LONG_SAMPLE_FILEPATH, LONG_SAMPLE_FILENAME, '885')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crawl through folders, applying transform pipeline to each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/tyler/2TB SSD/Samples/Splice - TYX/sounds/packs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_num, (root, dirs, files) in enumerate(os.walk(DATA_PATH)):\n",
    "    for file_num, file in enumerate(files):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_id: str = str(dir_num + 1) + str(file_num + 1)\n",
    "            process_sample(root, file, file_id)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87c1d7f5e1ccccee12e5578f273ffc9389e1f93823c720f1af1a96a1bb04cc3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
